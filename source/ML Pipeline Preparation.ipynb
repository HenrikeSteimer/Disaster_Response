{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ML Pipeline Preparation\n",
    "Follow the instructions below to help you create your ML pipeline.\n",
    "### 1. Import libraries and load data from database.\n",
    "- Import Python libraries\n",
    "- Load dataset from database with [`read_sql_table`](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.read_sql_table.html)\n",
    "- Define feature and target variables X and Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import pickle\n",
    "\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data from database\n",
    "engine = create_engine('sqlite:///Messages_and_categories.db')\n",
    "\n",
    "df = pd.read_sql('SELECT * FROM Messages_and_categories', engine)\n",
    "X = df['message'].values\n",
    "y = df.drop(['id','message','original','genre'], axis=1)\n",
    "feature_names = list(y.columns.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is a multi-class problem (several outcome variables). What are the outcomes?\n",
    "feature_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Are the categories mutually exclusive? No, this is a multi-label classification.\n",
    "y.sum(axis=1).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Which categories are likely?\n",
    "y.sum(axis=0).sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Write a tokenization function to process your text data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(text):\n",
    "    tokens = word_tokenize(text)\n",
    "    \n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "    clean_tokens = []\n",
    "    for tok in tokens:\n",
    "        clean_tok = lemmatizer.lemmatize(tok).lower().strip()\n",
    "        clean_tokens.append(clean_tok)\n",
    "\n",
    "    return clean_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['weather',\n",
       " 'update',\n",
       " '-',\n",
       " 'a',\n",
       " 'cold',\n",
       " 'front',\n",
       " 'from',\n",
       " 'cuba',\n",
       " 'that',\n",
       " 'could',\n",
       " 'pas',\n",
       " 'over',\n",
       " 'haiti']"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = tokenize(X[0])\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_pipeline():\n",
    "    pipeline = Pipeline([\n",
    "        ('vect', CountVectorizer(tokenizer=tokenize)),\n",
    "        ('tfidf', TfidfTransformer()),\n",
    "        ('clf', MultiOutputClassifier(RandomForestClassifier()))\n",
    "        ])\n",
    "    return pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Train pipeline\n",
    "- Split data into train and test sets\n",
    "- Train pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('vect',\n",
       "                 CountVectorizer(analyzer='word', binary=False,\n",
       "                                 decode_error='strict',\n",
       "                                 dtype=<class 'numpy.int64'>, encoding='utf-8',\n",
       "                                 input='content', lowercase=True, max_df=1.0,\n",
       "                                 max_features=None, min_df=1,\n",
       "                                 ngram_range=(1, 1), preprocessor=None,\n",
       "                                 stop_words=None, strip_accents=None,\n",
       "                                 token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "                                 tokenizer=<function tokenize at...\n",
       "                                                                        ccp_alpha=0.0,\n",
       "                                                                        class_weight=None,\n",
       "                                                                        criterion='gini',\n",
       "                                                                        max_depth=None,\n",
       "                                                                        max_features='auto',\n",
       "                                                                        max_leaf_nodes=None,\n",
       "                                                                        max_samples=None,\n",
       "                                                                        min_impurity_decrease=0.0,\n",
       "                                                                        min_impurity_split=None,\n",
       "                                                                        min_samples_leaf=1,\n",
       "                                                                        min_samples_split=2,\n",
       "                                                                        min_weight_fraction_leaf=0.0,\n",
       "                                                                        n_estimators=100,\n",
       "                                                                        n_jobs=None,\n",
       "                                                                        oob_score=False,\n",
       "                                                                        random_state=None,\n",
       "                                                                        verbose=0,\n",
       "                                                                        warm_start=False),\n",
       "                                       n_jobs=None))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = model_pipeline()\n",
    "model.fit(X_train, y_train)"
   ]
  },
    "### 5. Test your model\n",
    "Report the f1 score, precision and recall for each output category of the dataset. You can do this by iterating through the columns and calling sklearn's `classification_report` on each."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = pd.DataFrame(data=y_pred, columns=feature_names)\n",
    "y_test = pd.DataFrame(data=y_test, columns=feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "---- related ----\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.27      0.39      1524\n",
      "           1       0.81      0.98      0.88      4979\n",
      "           2       1.00      0.08      0.15        51\n",
      "\n",
      "    accuracy                           0.80      6554\n",
      "   macro avg       0.86      0.44      0.47      6554\n",
      "weighted avg       0.80      0.80      0.76      6554\n",
      "\n",
      "\n",
      "\n",
      "---- request ----\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.99      0.94      5410\n",
      "           1       0.90      0.42      0.57      1144\n",
      "\n",
      "    accuracy                           0.89      6554\n",
      "   macro avg       0.89      0.71      0.75      6554\n",
      "weighted avg       0.89      0.89      0.87      6554\n",
      "\n",
      "\n",
      "\n",
      "---- offer ----\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      6523\n",
      "           1       0.00      0.00      0.00        31\n",
      "\n",
      "    accuracy                           1.00      6554\n",
      "   macro avg       0.50      0.50      0.50      6554\n",
      "weighted avg       0.99      1.00      0.99      6554\n",
      "\n",
      "\n",
      "\n",
      "---- aid_related ----\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.88      0.81      3851\n",
      "           1       0.77      0.60      0.68      2703\n",
      "\n",
      "    accuracy                           0.76      6554\n",
      "   macro avg       0.77      0.74      0.75      6554\n",
      "weighted avg       0.76      0.76      0.76      6554\n",
      "\n",
      "\n",
      "\n",
      "---- medical_help ----\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96      6024\n",
      "           1       0.79      0.06      0.11       530\n",
      "\n",
      "    accuracy                           0.92      6554\n",
      "   macro avg       0.86      0.53      0.53      6554\n",
      "weighted avg       0.91      0.92      0.89      6554\n",
      "\n",
      "\n",
      "\n",
      "---- medical_products ----\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      1.00      0.98      6238\n",
      "           1       0.73      0.05      0.09       316\n",
      "\n",
      "    accuracy                           0.95      6554\n",
      "   macro avg       0.84      0.52      0.54      6554\n",
      "weighted avg       0.94      0.95      0.93      6554\n",
      "\n",
      "\n",
      "\n",
      "---- search_and_rescue ----\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      1.00      0.99      6366\n",
      "           1       0.79      0.06      0.11       188\n",
      "\n",
      "    accuracy                           0.97      6554\n",
      "   macro avg       0.88      0.53      0.55      6554\n",
      "weighted avg       0.97      0.97      0.96      6554\n",
      "\n",
      "\n",
      "\n",
      "---- security ----\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99      6445\n",
      "           1       0.50      0.01      0.02       109\n",
      "\n",
      "    accuracy                           0.98      6554\n",
      "   macro avg       0.74      0.50      0.50      6554\n",
      "weighted avg       0.98      0.98      0.98      6554\n",
      "\n",
      "\n",
      "\n",
      "---- military ----\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      1.00      0.98      6337\n",
      "           1       0.80      0.06      0.10       217\n",
      "\n",
      "    accuracy                           0.97      6554\n",
      "   macro avg       0.88      0.53      0.54      6554\n",
      "weighted avg       0.96      0.97      0.95      6554\n",
      "\n",
      "\n",
      "\n",
      "---- child_alone ----\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      6554\n",
      "\n",
      "    accuracy                           1.00      6554\n",
      "   macro avg       1.00      1.00      1.00      6554\n",
      "weighted avg       1.00      1.00      1.00      6554\n",
      "\n",
      "\n",
      "\n",
      "---- water ----\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      1.00      0.98      6141\n",
      "           1       0.92      0.27      0.42       413\n",
      "\n",
      "    accuracy                           0.95      6554\n",
      "   macro avg       0.94      0.63      0.70      6554\n",
      "weighted avg       0.95      0.95      0.94      6554\n",
      "\n",
      "\n",
      "\n",
      "---- food ----\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.99      0.96      5812\n",
      "           1       0.89      0.42      0.57       742\n",
      "\n",
      "    accuracy                           0.93      6554\n",
      "   macro avg       0.91      0.70      0.76      6554\n",
      "weighted avg       0.93      0.93      0.92      6554\n",
      "\n",
      "\n",
      "\n",
      "---- shelter ----\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      1.00      0.96      6003\n",
      "           1       0.83      0.23      0.36       551\n",
      "\n",
      "    accuracy                           0.93      6554\n",
      "   macro avg       0.88      0.61      0.66      6554\n",
      "weighted avg       0.92      0.93      0.91      6554\n",
      "\n",
      "\n",
      "\n",
      "---- clothing ----\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99      6447\n",
      "           1       0.57      0.04      0.07       107\n",
      "\n",
      "    accuracy                           0.98      6554\n",
      "   macro avg       0.78      0.52      0.53      6554\n",
      "weighted avg       0.98      0.98      0.98      6554\n",
      "\n",
      "\n",
      "\n",
      "---- money ----\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99      6399\n",
      "           1       0.83      0.03      0.06       155\n",
      "\n",
      "    accuracy                           0.98      6554\n",
      "   macro avg       0.91      0.52      0.53      6554\n",
      "weighted avg       0.97      0.98      0.97      6554\n",
      "\n",
      "\n",
      "\n",
      "---- missing_people ----\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99      6476\n",
      "           1       1.00      0.01      0.03        78\n",
      "\n",
      "    accuracy                           0.99      6554\n",
      "   macro avg       0.99      0.51      0.51      6554\n",
      "weighted avg       0.99      0.99      0.98      6554\n",
      "\n",
      "\n",
      "\n",
      "---- refugees ----\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      1.00      0.99      6373\n",
      "           1       0.43      0.02      0.03       181\n",
      "\n",
      "    accuracy                           0.97      6554\n",
      "   macro avg       0.70      0.51      0.51      6554\n",
      "weighted avg       0.96      0.97      0.96      6554\n",
      "\n",
      "\n",
      "\n",
      "---- death ----\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      1.00      0.98      6249\n",
      "           1       0.89      0.13      0.22       305\n",
      "\n",
      "    accuracy                           0.96      6554\n",
      "   macro avg       0.92      0.56      0.60      6554\n",
      "weighted avg       0.96      0.96      0.94      6554\n",
      "\n",
      "\n",
      "\n",
      "---- other_aid ----\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      1.00      0.93      5670\n",
      "           1       0.65      0.01      0.02       884\n",
      "\n",
      "    accuracy                           0.87      6554\n",
      "   macro avg       0.76      0.51      0.48      6554\n",
      "weighted avg       0.84      0.87      0.81      6554\n",
      "\n",
      "\n",
      "\n",
      "---- infrastructure_related ----\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      1.00      0.97      6128\n",
      "           1       0.00      0.00      0.00       426\n",
      "\n",
      "    accuracy                           0.93      6554\n",
      "   macro avg       0.47      0.50      0.48      6554\n",
      "weighted avg       0.87      0.93      0.90      6554\n",
      "\n",
      "\n",
      "\n",
      "---- transport ----\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      1.00      0.98      6231\n",
      "           1       0.72      0.09      0.16       323\n",
      "\n",
      "    accuracy                           0.95      6554\n",
      "   macro avg       0.84      0.54      0.57      6554\n",
      "weighted avg       0.94      0.95      0.94      6554\n",
      "\n",
      "\n",
      "\n",
      "---- buildings ----\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      1.00      0.98      6231\n",
      "           1       0.74      0.09      0.16       323\n",
      "\n",
      "    accuracy                           0.95      6554\n",
      "   macro avg       0.85      0.54      0.57      6554\n",
      "weighted avg       0.94      0.95      0.94      6554\n",
      "\n",
      "\n",
      "\n",
      "---- electricity ----\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99      6427\n",
      "           1       0.67      0.02      0.03       127\n",
      "\n",
      "    accuracy                           0.98      6554\n",
      "   macro avg       0.82      0.51      0.51      6554\n",
      "weighted avg       0.97      0.98      0.97      6554\n",
      "\n",
      "\n",
      "\n",
      "---- tools ----\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      1.00      6514\n",
      "           1       0.00      0.00      0.00        40\n",
      "\n",
      "    accuracy                           0.99      6554\n",
      "   macro avg       0.50      0.50      0.50      6554\n",
      "weighted avg       0.99      0.99      0.99      6554\n",
      "\n",
      "\n",
      "\n",
      "---- hospitals ----\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99      6482\n",
      "           1       0.00      0.00      0.00        72\n",
      "\n",
      "    accuracy                           0.99      6554\n",
      "   macro avg       0.49      0.50      0.50      6554\n",
      "weighted avg       0.98      0.99      0.98      6554\n",
      "\n",
      "\n",
      "\n",
      "---- shops ----\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      6529\n",
      "           1       0.00      0.00      0.00        25\n",
      "\n",
      "    accuracy                           1.00      6554\n",
      "   macro avg       0.50      0.50      0.50      6554\n",
      "weighted avg       0.99      1.00      0.99      6554\n",
      "\n",
      "\n",
      "\n",
      "---- aid_centers ----\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99      6487\n",
      "           1       0.00      0.00      0.00        67\n",
      "\n",
      "    accuracy                           0.99      6554\n",
      "   macro avg       0.49      0.50      0.50      6554\n",
      "weighted avg       0.98      0.99      0.98      6554\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/henrikesteimer/opt/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "---- other_infrastructure ----\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      1.00      0.98      6251\n",
      "           1       0.00      0.00      0.00       303\n",
      "\n",
      "    accuracy                           0.95      6554\n",
      "   macro avg       0.48      0.50      0.49      6554\n",
      "weighted avg       0.91      0.95      0.93      6554\n",
      "\n",
      "\n",
      "\n",
      "---- weather_related ----\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.96      0.91      4772\n",
      "           1       0.85      0.62      0.72      1782\n",
      "\n",
      "    accuracy                           0.87      6554\n",
      "   macro avg       0.86      0.79      0.81      6554\n",
      "weighted avg       0.87      0.87      0.86      6554\n",
      "\n",
      "\n",
      "\n",
      "---- floods ----\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      1.00      0.97      6033\n",
      "           1       0.92      0.34      0.50       521\n",
      "\n",
      "    accuracy                           0.95      6554\n",
      "   macro avg       0.93      0.67      0.73      6554\n",
      "weighted avg       0.94      0.95      0.93      6554\n",
      "\n",
      "\n",
      "\n",
      "---- storm ----\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.99      0.96      5937\n",
      "           1       0.79      0.41      0.54       617\n",
      "\n",
      "    accuracy                           0.93      6554\n",
      "   macro avg       0.87      0.70      0.75      6554\n",
      "weighted avg       0.93      0.93      0.92      6554\n",
      "\n",
      "\n",
      "\n",
      "---- fire ----\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      1.00      6491\n",
      "           1       0.00      0.00      0.00        63\n",
      "\n",
      "    accuracy                           0.99      6554\n",
      "   macro avg       0.50      0.50      0.50      6554\n",
      "weighted avg       0.98      0.99      0.99      6554\n",
      "\n",
      "\n",
      "\n",
      "---- earthquake ----\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.99      0.98      5968\n",
      "           1       0.91      0.72      0.80       586\n",
      "\n",
      "    accuracy                           0.97      6554\n",
      "   macro avg       0.94      0.85      0.89      6554\n",
      "weighted avg       0.97      0.97      0.97      6554\n",
      "\n",
      "\n",
      "\n",
      "---- cold ----\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99      6436\n",
      "           1       0.70      0.06      0.11       118\n",
      "\n",
      "    accuracy                           0.98      6554\n",
      "   macro avg       0.84      0.53      0.55      6554\n",
      "weighted avg       0.98      0.98      0.98      6554\n",
      "\n",
      "\n",
      "\n",
      "---- other_weather ----\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      1.00      0.97      6212\n",
      "           1       0.57      0.01      0.02       342\n",
      "\n",
      "    accuracy                           0.95      6554\n",
      "   macro avg       0.76      0.51      0.50      6554\n",
      "weighted avg       0.93      0.95      0.92      6554\n",
      "\n",
      "\n",
      "\n",
      "---- direct_report ----\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.99      0.92      5307\n",
      "           1       0.85      0.36      0.51      1247\n",
      "\n",
      "    accuracy                           0.87      6554\n",
      "   macro avg       0.86      0.67      0.72      6554\n",
      "weighted avg       0.86      0.87      0.84      6554\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for column in y.columns:\n",
    "    print('\\n---- {} ----\\n{}\\n'.format(column, classification_report(y_test[column], y_pred[column])))"
   ]
  },
